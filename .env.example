####################################
#### Server & DB Configurations ####
####################################

# Cache Configs
CACHE_STORE=database # Defaults to database. Other available cache store: redis and filesystem
REDIS_URL=           # Redis URL - could be a local redis instance or cloud hosted redis. Also support rediss:// URLs
PGLITE_DATA_DIR=     #../pgLite/ if selecting a directory   --- or memory:// if selecting in memory

# Eliza Port Config
SERVER_PORT=3000
VITE_SERVER_PORT=${SERVER_PORT}

# Supabase Configuration
SUPABASE_URL=
SUPABASE_ANON_KEY=

# Comma separated list of remote character urls (optional)
REMOTE_CHARACTER_URLS=

# Stores characters set by using the direct API in the data/character folder for further load when the app restarts
USE_CHARACTER_STORAGE=false

# Logging
DEFAULT_LOG_LEVEL=warn
LOG_JSON_FORMAT=false            # Print everything in logger as json; false by default

######################################
#### Crypto Plugin Configurations ####
######################################

# CoinMarketCap / CMC
COINMARKETCAP_API_KEY=

# CoinGecko
COINGECKO_API_KEY=
COINGECKO_PRO_API_KEY=

# EVM
EVM_PRIVATE_KEY=
EVM_PROVIDER_URL=

# Avalanche
AVALANCHE_PRIVATE_KEY=
AVALANCHE_PUBLIC_KEY=

# Arthera
ARTHERA_PRIVATE_KEY=

# Solana
SOLANA_PRIVATE_KEY=
SOLANA_PUBLIC_KEY=
SOLANA_CLUSTER=           # Default: devnet. Solana Cluster: 'devnet' | 'testnet' | 'mainnet-beta'
SOLANA_ADMIN_PRIVATE_KEY= # This wallet is used to verify NFTs
SOLANA_ADMIN_PUBLIC_KEY=  # This wallet is used to verify NFTs
SOLANA_VERIFY_TOKEN=      # Authentication token for calling the verification API

# Injective
INJECTIVE_PRIVATE_KEY= #
INJECTIVE_PUBLIC_KEY= #
INJECTIVE_NETWORK= #
# Fallback Wallet Configuration (deprecated)
WALLET_PRIVATE_KEY=
WALLET_PUBLIC_KEY=

BIRDEYE_API_KEY=

# Solana Configuration
SOL_ADDRESS=So11111111111111111111111111111111111111112
SLIPPAGE=1
BASE_MINT=So11111111111111111111111111111111111111112
SOLANA_RPC_URL=https://api.mainnet-beta.solana.com
HELIUS_API_KEY=

###############################
#### Client Configurations ####
###############################

# Discord Configuration
DISCORD_APPLICATION_ID=
DISCORD_API_TOKEN=        # Bot token
DISCORD_VOICE_CHANNEL_ID= # The ID of the voice channel the bot should join (optional)

# Devin Configuration
DEVIN_API_TOKEN=         # Get your API key from docs.devin.ai/tutorials/api-integration

# Farcaster Neynar Configuration
FARCASTER_FID=                # The FID associated with the account your are sending casts from
FARCASTER_NEYNAR_API_KEY=     # Neynar API key: https://neynar.com/
FARCASTER_NEYNAR_SIGNER_UUID= # Signer for the account you are sending casts from. Create a signer here: https://dev.neynar.com/app
FARCASTER_DRY_RUN=false       # Set to true if you want to run the bot without actually publishing casts
FARCASTER_POLL_INTERVAL=120   # How often (in seconds) the bot should check for farcaster interactions (replies and mentions)

# Telegram Configuration
TELEGRAM_BOT_TOKEN=

# Twitter/X Configuration
TWITTER_DRY_RUN=false
TWITTER_USERNAME= # Account username
TWITTER_PASSWORD= # Account password
TWITTER_EMAIL=    # Account email
TWITTER_2FA_SECRET=
TWITTER_POLL_INTERVAL=120   # How often (in seconds) the bot should check for interactions
TWITTER_SEARCH_ENABLE=FALSE # Enable timeline search, WARNING this greatly increases your chance of getting banned
TWITTER_TARGET_USERS=       # Comma separated list of Twitter user names to interact with
TWITTER_RETRY_LIMIT=        # Maximum retry attempts for Twitter login
TWITTER_SPACES_ENABLE=false # Enable or disable Twitter Spaces logic
# Post Interval Settings (in minutes)
POST_INTERVAL_MIN= # Default: 90
POST_INTERVAL_MAX= # Default: 180
POST_IMMEDIATELY=  # Default: false
# Twitter action processing configuration
ACTION_INTERVAL=               # Interval in minutes between action processing runs (default: 5 minutes)
ENABLE_ACTION_PROCESSING=false # Set to true to enable the action processing loop
MAX_ACTIONS_PROCESSING=1       # Maximum number of actions (e.g., retweets, likes) to process in a single cycle. Helps prevent excessive or uncontrolled actions.
ACTION_TIMELINE_TYPE=foryou    # Type of timeline to interact with. Options: "foryou" or "following". Default: "foryou"
# CONFIGURATION FOR APPROVING TWEETS BEFORE IT GETS POSTED
TWITTER_APPROVAL_DISCORD_CHANNEL_ID=  # Channel ID for the Discord bot to listen and send approval messages
TWITTER_APPROVAL_DISCORD_BOT_TOKEN=   # Discord bot token (this could be a different bot token from DISCORD_API_TOKEN)
TWITTER_APPROVAL_ENABLED=             # Enable or disable Twitter approval logic #Default is false
TWITTER_APPROVAL_CHECK_INTERVAL=60000 # Default: 60 seconds

# WhatsApp Cloud API Configuration
WHATSAPP_ACCESS_TOKEN=         # Permanent access token from Facebook Developer Console
WHATSAPP_PHONE_NUMBER_ID=      # Phone number ID from WhatsApp Business API
WHATSAPP_BUSINESS_ACCOUNT_ID=  # Business Account ID from Facebook Business Manager
WHATSAPP_WEBHOOK_VERIFY_TOKEN= # Custom string for webhook verification
WHATSAPP_API_VERSION=v17.0     # WhatsApp API version (default: v17.0)


# Simsai Specific Configuration
SIMSAI_API_KEY= # API key for SimsAI authentication
SIMSAI_AGENT_ID= # Unique identifier for the SimsAI agent
SIMSAI_USERNAME= # Username for SimsAI platform access
SIMSAI_DRY_RUN= # Set to true to test without making actual API calls

# Direct Client Setting
EXPRESS_MAX_PAYLOAD= # Default: 100kb

#######################################
#### Model Provider Configurations ####
#######################################

# OpenAI Configuration
OPENAI_API_KEY=         # OpenAI API key, starting with sk-
OPENAI_API_URL=         # OpenAI API Endpoint (optional), Default: https://api.openai.com/v1
SMALL_OPENAI_MODEL=     # Default: gpt-4o-mini
MEDIUM_OPENAI_MODEL=    # Default: gpt-4o
LARGE_OPENAI_MODEL=     # Default: gpt-4o
EMBEDDING_OPENAI_MODEL= # Default: text-embedding-3-small
IMAGE_OPENAI_MODEL=     # Default: dall-e-3
USE_OPENAI_EMBEDDING=TRUE   # Set to TRUE for OpenAI/1536, leave blank for local

# Community Plugin for OpenAI Configuration
ENABLE_OPEN_AI_COMMUNITY_PLUGIN=false
OPENAI_DEFAULT_MODEL=
OPENAI_MAX_TOKENS=
OPENAI_TEMPERATURE=




# Atoma SDK Configuration
ATOMASDK_BEARER_AUTH=           # Atoma SDK Bearer Auth token
ATOMA_API_URL=                  # Default: https://api.atoma.network/v1
SMALL_ATOMA_MODEL=              # Default: meta-llama/Llama-3.3-70B-Instruct
MEDIUM_ATOMA_MODEL=             # Default: meta-llama/Llama-3.3-70B-Instruct
LARGE_ATOMA_MODEL=              # Default: meta-llama/Llama-3.3-70B-Instruct

# Eternal AI's Decentralized Inference API
ETERNALAI_URL=
ETERNALAI_MODEL=                    # Default: "NousResearch/Hermes-3-Llama-3.1-70B-FP8"
ETERNALAI_CHAIN_ID=8453            # Default: "8453"
ETERNALAI_RPC_URL=                  # Ex: https://mainnet.base.org/
ETERNALAI_AGENT_CONTRACT_ADDRESS=   # Ex: 0xAed016e060e2fFE3092916b1650Fc558D62e1CCC
ETERNALAI_AGENT_ID=                 # Ex: 1711
ETERNALAI_API_KEY=
ETERNALAI_LOG=false #Default: false

# Hyperbolic Configuration
HYPERBOLIC_API_KEY= # Hyperbolic API Key
HYPERBOLIC_MODEL=
IMAGE_HYPERBOLIC_MODEL=  # Default: FLUX.1-dev
SMALL_HYPERBOLIC_MODEL=  # Default: meta-llama/Llama-3.2-3B-Instruct
MEDIUM_HYPERBOLIC_MODEL= # Default: meta-llama/Meta-Llama-3.1-70B-Instruct
LARGE_HYPERBOLIC_MODEL=  # Default: meta-llama/Meta-Llama-3.1-405-Instruct

# Infera Configuration
INFERA_API_KEY=      # visit api.infera.org/docs to obtain an API key under /signup_user
INFERA_MODEL=        # Default: llama3.2:latest
INFERA_SERVER_URL=   # Default: https://api.infera.org/
SMALL_INFERA_MODEL=  #Recommended: llama3.2:latest
MEDIUM_INFERA_MODEL= #Recommended: mistral-nemo:latest
LARGE_INFERA_MODEL=  #Recommended: mistral-small:latest

# Venice Configuration
VENICE_API_KEY=      # generate from venice settings
SMALL_VENICE_MODEL=  # Default: llama-3.3-70b
MEDIUM_VENICE_MODEL= # Default: llama-3.3-70b
LARGE_VENICE_MODEL=  # Default: llama-3.1-405b
IMAGE_VENICE_MODEL=  # Default: fluently-xl

# Nineteen.ai Configuration
NINETEEN_AI_API_KEY=      # Get a free api key from https://nineteen.ai/app/api
SMALL_NINETEEN_AI_MODEL=  # Default: unsloth/Llama-3.2-3B-Instruct
MEDIUM_NINETEEN_AI_MODEL= # Default: unsloth/Meta-Llama-3.1-8B-Instruct
LARGE_NINETEEN_AI_MODEL=  # Default: hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4
IMAGE_NINETEEN_AI_MODE=   # Default: dataautogpt3/ProteusV0.4-Lightning

# Akash Chat API Configuration docs: https://chatapi.akash.network/documentation
AKASH_CHAT_API_KEY=          # Get from https://chatapi.akash.network/
SMALL_AKASH_CHAT_API_MODEL=  # Default: Meta-Llama-3-2-3B-Instruct
MEDIUM_AKASH_CHAT_API_MODEL= # Default: Meta-Llama-3-3-70B-Instruct
LARGE_AKASH_CHAT_API_MODEL=  # Default: Meta-Llama-3-1-405B-Instruct-FP8

# Livepeer configuration

LIVEPEER_GATEWAY_URL=https://dream-gateway.livepeer.cloud           # Free inference gateways and docs: https://livepeer-eliza.com/
IMAGE_LIVEPEER_MODEL=           # Default: ByteDance/SDXL-Lightning
SMALL_LIVEPEER_MODEL=           # Default: meta-llama/Meta-Llama-3.1-8B-Instruct
MEDIUM_LIVEPEER_MODEL=          # Default: meta-llama/Meta-Llama-3.1-8B-Instruct
LARGE_LIVEPEER_MODEL=           # Default: meta-llama/Meta-Llama-3.1-8B-Instruct

# Speech Synthesis
ELEVENLABS_XI_API_KEY= # API key from elevenlabs

# Transcription Provider
TRANSCRIPTION_PROVIDER= # Default: local (possible values: openai, deepgram, local)

# ElevenLabs Settings
ELEVENLABS_MODEL_ID=eleven_multilingual_v2
ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM
ELEVENLABS_VOICE_STABILITY=0.5
ELEVENLABS_VOICE_SIMILARITY_BOOST=0.9
ELEVENLABS_VOICE_STYLE=0.66
ELEVENLABS_VOICE_USE_SPEAKER_BOOST=false
ELEVENLABS_OPTIMIZE_STREAMING_LATENCY=4
ELEVENLABS_OUTPUT_FORMAT=pcm_16000

# OpenRouter Configuration
OPENROUTER_API_KEY= # OpenRouter API Key
OPENROUTER_MODEL=   # Default: uses hermes 70b/405b
SMALL_OPENROUTER_MODEL=
MEDIUM_OPENROUTER_MODEL=
LARGE_OPENROUTER_MODEL=

# REDPILL Configuration (https://docs.red-pill.ai/get-started/supported-models)
REDPILL_API_KEY= # REDPILL API Key
REDPILL_MODEL=
SMALL_REDPILL_MODEL=  # Default: gpt-4o-mini
MEDIUM_REDPILL_MODEL= # Default: gpt-4o
LARGE_REDPILL_MODEL=  # Default: gpt-4o

# Grok Configuration
GROK_API_KEY=         # GROK/xAI API Key
SMALL_GROK_MODEL=     # Default: grok-2-1212
MEDIUM_GROK_MODEL=    # Default: grok-2-1212
LARGE_GROK_MODEL=     # Default: grok-2-1212
EMBEDDING_GROK_MODEL= # Default: grok-2-1212

# Ollama Configuration
OLLAMA_SERVER_URL= # Default: localhost:11434
OLLAMA_MODEL=
USE_OLLAMA_EMBEDDING=   # Set to TRUE for OLLAMA/1024, leave blank for local
OLLAMA_EMBEDDING_MODEL= # Default: mxbai-embed-large
SMALL_OLLAMA_MODEL=     # Default: llama3.2
MEDIUM_OLLAMA_MODEL=    # Default: hermes3
LARGE_OLLAMA_MODEL=     # Default: hermes3:70b

# Google Configuration
GOOGLE_MODEL=
SMALL_GOOGLE_MODEL=     # Default: gemini-1.5-flash-latest
MEDIUM_GOOGLE_MODEL=    # Default: gemini-1.5-flash-latest
LARGE_GOOGLE_MODEL=     # Default: gemini-1.5-pro-latest
EMBEDDING_GOOGLE_MODEL= # Default: text-embedding-004

# Mistral Configuration
MISTRAL_MODEL=
SMALL_MISTRAL_MODEL=  # Default: mistral-small-latest
MEDIUM_MISTRAL_MODEL= # Default: mistral-large-latest
LARGE_MISTRAL_MODEL=  # Default: mistral-large-latest

# Groq Configuration
GROQ_API_KEY=         # Starts with gsk_
SMALL_GROQ_MODEL=     # Default: llama-3.1-8b-instant
MEDIUM_GROQ_MODEL=    # Default: llama-3.3-70b-versatile
LARGE_GROQ_MODEL=     # Default: llama-3.2-90b-vision-preview
EMBEDDING_GROQ_MODEL= # Default: llama-3.1-8b-instant

# LlamaLocal Configuration
LLAMALOCAL_PATH= # Default: "" which is the current directory in plugin-node/dist/ which gets destroyed and recreated on every build

# NanoGPT Configuration
SMALL_NANOGPT_MODEL=  # Default: gpt-4o-mini
MEDIUM_NANOGPT_MODEL= # Default: gpt-4o
LARGE_NANOGPT_MODEL=  # Default: gpt-4o

# Anthropic Configuration
ANTHROPIC_API_KEY=      # For Claude
SMALL_ANTHROPIC_MODEL=  # Default: claude-3-haiku-20240307
MEDIUM_ANTHROPIC_MODEL= # Default: claude-3-5-sonnet-20241022
LARGE_ANTHROPIC_MODEL=  # Default: claude-3-5-sonnet-20241022

# Heurist Configuration
HEURIST_API_KEY=      # Get from https://heurist.ai/dev-access
SMALL_HEURIST_MODEL=  # Default: meta-llama/llama-3-70b-instruct
MEDIUM_HEURIST_MODEL= # Default: meta-llama/llama-3-70b-instruct
LARGE_HEURIST_MODEL=  # Default: meta-llama/llama-3.3-70b-instruct
HEURIST_IMAGE_MODEL=  # Default: FLUX.1-dev
HEURIST_EMBEDDING_MODEL= # Default: BAAI/bge-large-en-v1.5
USE_HEURIST_EMBEDDING= # Set to TRUE for HEURIST embedding, leave blank for local

# Gaianet Configuration
GAIANET_MODEL=
GAIANET_SERVER_URL=
SMALL_GAIANET_MODEL=       # Default: llama3b
SMALL_GAIANET_SERVER_URL=  # Default: https://llama3b.gaia.domains/v1
MEDIUM_GAIANET_MODEL=      # Default: llama
MEDIUM_GAIANET_SERVER_URL= # Default: https://llama8b.gaia.domains/v1
LARGE_GAIANET_MODEL=       # Default: qwen72b
LARGE_GAIANET_SERVER_URL=  # Default: https://qwen72b.gaia.domains/v1
GAIANET_EMBEDDING_MODEL=
USE_GAIANET_EMBEDDING= # Set to TRUE for GAIANET/768, leave blank for local

# Volcengine Configuration
VOLENGINE_API_URL= # Volcengine API Endpoint, Default: https://open.volcengineapi.com/api/v3/
VOLENGINE_MODEL=
SMALL_VOLENGINE_MODEL=     # Default: doubao-lite-128k
MEDIUM_VOLENGINE_MODEL=    # Default: doubao-pro-128k
LARGE_VOLENGINE_MODEL=     # Default: doubao-pro-256k
VOLENGINE_EMBEDDING_MODEL= # Default: doubao-embedding

# DeepSeek Configuration
DEEPSEEK_API_KEY=      #Your DeepSeek API key
DEEPSEEK_API_URL=      # Default: https://api.deepseek.com
SMALL_DEEPSEEK_MODEL=  # Default: deepseek-chat
MEDIUM_DEEPSEEK_MODEL= # Default: deepseek-chat
LARGE_DEEPSEEK_MODEL=  # Default: deepseek-chat

# fal.ai Configuration
FAL_API_KEY=
FAL_AI_LORA_PATH=

# LetzAI Configuration
LETZAI_API_KEY= # LetzAI API Key
LETZAI_MODELS=  # list of Letzai models to add to each prompt, e.g.: "@modelname1, @modelname2"

# Galadriel Configuration
GALADRIEL_API_KEY=gal-*      # Get from https://dashboard.galadriel.com/
SMALL_GALADRIEL_MODEL=       # Default: gpt-4o-mini
MEDIUM_GALADRIEL_MODEL=      # Default: gpt-4o
LARGE_GALADRIEL_MODEL=       # Default: gpt-4o
GALADRIEL_FINE_TUNE_API_KEY= # Use an OpenAI key to use a fine-tuned model with the verified inference endpoint

# Remaining Provider Configurations
GOOGLE_GENERATIVE_AI_API_KEY= # Gemini API key
ALI_BAILIAN_API_KEY=          # Ali Bailian API Key
NANOGPT_API_KEY=              # NanoGPT API Key
TOGETHER_API_KEY=             # Together API Key